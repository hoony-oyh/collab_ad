{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data_files_list = [\"data/ids2018_processed/Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "                   \"data/ids2018_processed/Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\", \n",
    "                   \"data/ids2018_processed/Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\",                   \n",
    "                   \"data/ids2018_processed/Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "                   \"data/ids2018_processed/Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "                   \"data/ids2018_processed/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\"]\n",
    "\n",
    "dtypes = {'dst_port': 'int', 'protocol': 'int', 'timestamp': 'str', 'fl_dur': 'int',\n",
    "     'tot_fw_pk': 'int', 'tot_bw_pk': 'int', 'tot_l_fw_pkt': 'int', 'tot_l_bw_pkt': 'int', \n",
    "     'fw_pkt_l_max': 'int', 'fw_pkt_l_min': 'int', 'fw_pkt_l_avg': 'float', 'fw_pkt_l_std': 'float',\n",
    "     'bw_pkt_l_max': 'int', 'bw_pkt_l_min': 'int', 'bw_pkt_l_avg': 'float', 'bw_pkt_l_std': 'float', \n",
    "     'fl_byt_s': 'float', 'fl_pkt_s': 'float', \n",
    "     'fl_iat_avg': 'float', 'fl_iat_std': 'float', 'fl_iat_max': 'int', 'fl_iat_min': 'int',\n",
    "     'fw_iat_tot': 'int', 'fw_iat_avg': 'float', 'fw_iat_std': 'float', 'fw_iat_max': 'int', 'fw_iat_min': 'int',\n",
    "     'bw_iat_tot': 'int', 'bw_iat_avg': 'float', 'bw_iat_std': 'float', 'bw_iat_max': 'int', 'bw_iat_min': 'int',\n",
    "     'fw_psh_flag': 'int', 'bw_psh_flag': 'int', 'fw_urg_flag': 'int', 'bw_urg_flag': 'int',\n",
    "     'fw_hdr_len': 'int', 'bw_hdr_len': 'int', 'fw_pkt_s': 'float', 'bw_pkt_s': 'float', \n",
    "     'pkt_len_min': 'int', 'pkt_len_max': 'int', 'pkt_len_avg': 'float', 'pkt_len_std': 'float', 'pkt_len_var': 'float', \n",
    "     'fin_cnt': 'int', 'syn_cnt': 'int', 'rst_cnt': 'int', 'pst_cnt': 'int', \n",
    "     'ack_cnt': 'int', 'urg_cnt': 'int', 'cwe_cnt': 'int', 'ece_cnt': 'int', \n",
    "     'down_up_ratio': 'float', 'pkt_size_avg': 'float', 'fw_seg_avg': 'float', 'bw_seg_avg': 'float', \n",
    "     'fw_byt_blk_avg': 'float', 'fw_pkt_blk_avg': 'float', 'fw_blk_rate_avg': 'float', \n",
    "     'bw_byt_blk_avg': 'float', 'bw_pkt_blk_avg': 'float', 'bw_blk_rate_avg': 'float', \n",
    "     'subfl_fw_pk': 'int', 'subfl_fw_byt': 'int', 'subfl_bw_pkt': 'int', 'subfl_bw_byt': 'int',\n",
    "     'fw_win_byt': 'int', 'bw_win_byt': 'int', 'fw_act_pkt': 'int', 'fw_seg_min': 'int', \n",
    "     'atv_avg': 'float', 'atv_std': 'float', 'atv_max': 'int', 'atv_min': 'int', \n",
    "     'idl_avg': 'float', 'idl_std': 'float', 'idl_max': 'int', 'idl_min': 'int', \n",
    "     'label': 'str'}\n",
    "\n",
    "features = list(dtypes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"data/ids2018_collaborative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_user_num = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File >> data/ids2018_processed/Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "Raw file has 1048575 rows with 80 features\n",
      "Cleaned file has 1044751 rows with 57 features\n",
      "Number of benign data: 663808\n",
      "Number of malicious data: 380943\n",
      "\n",
      "File >> data/ids2018_processed/Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "Raw file has 1048575 rows with 80 features\n",
      "Cleaned file has 1040548 rows with 57 features\n",
      "Number of benign data: 988050\n",
      "Number of malicious data: 52498\n",
      "\n",
      "File >> data/ids2018_processed/Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "Raw file has 1048575 rows with 80 features\n",
      "Cleaned file has 1048575 rows with 57 features\n",
      "Number of benign data: 360833\n",
      "Number of malicious data: 687742\n",
      "\n",
      "File >> data/ids2018_processed/Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "Raw file has 1048575 rows with 80 features\n",
      "Cleaned file has 1042965 rows with 57 features\n",
      "Number of benign data: 1042603\n",
      "Number of malicious data: 362\n",
      "\n",
      "File >> data/ids2018_processed/Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "Raw file has 1048575 rows with 80 features\n",
      "Cleaned file has 1042867 rows with 57 features\n",
      "Number of benign data: 1042301\n",
      "Number of malicious data: 566\n",
      "\n",
      "File >> data/ids2018_processed/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\n",
      "Raw file has 1048575 rows with 80 features\n",
      "Cleaned file has 1044525 rows with 57 features\n",
      "Number of benign data: 758334\n",
      "Number of malicious data: 286191\n",
      "\n",
      "Total Statistics\n",
      "\tBenign Flows: 4855929(77.52%)\n",
      "\tMalicious Flows: 1408302(22.48%)\n"
     ]
    }
   ],
   "source": [
    "malicious_flows_list = []\n",
    "benign_flow_nums = []\n",
    "malicious_flow_nums = []\n",
    "for csv_path in data_files_list[:]:\n",
    "    # read the csv file\n",
    "    basename = csv_path.split(\"/\")[-1].replace('.csv', '')\n",
    "    flow_df = pd.read_csv(csv_path, skiprows=1, names=features, dtype=dtypes,\n",
    "                          parse_dates=['timestamp'], dayfirst=True, warn_bad_lines=True, error_bad_lines=False)\n",
    "    print(\"\\nFile >> {}\".format(csv_path))\n",
    "    print(\"Raw file has {} rows with {} features\".format(len(flow_df), len(flow_df.columns)))\n",
    "    \n",
    "    # preprocess (feature selection & cleaning)\n",
    "    filtered_features = [\"dst_port\", \"protocol\", \"timestamp\", \"fl_dur\", \"idl_avg\", \"idl_std\"]\n",
    "    selected_feature = [f for f in features if (\"min\" not in f and \"max\" not in f)]\n",
    "    for ff in filtered_features:\n",
    "        selected_feature.remove(ff)\n",
    "    preprocessed_df = flow_df[selected_feature]\n",
    "    \n",
    "    clean_df = preprocessed_df[~preprocessed_df.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "    print(\"Cleaned file has {} rows with {} features\".format(len(clean_df), len(clean_df.columns)))\n",
    "    \n",
    "    # get the benign flows\n",
    "    benign_flow_df = clean_df[clean_df['label'] == \"Benign\"]\n",
    "    benign_flow_nums.append(len(benign_flow_df))\n",
    "    print(\"Number of benign data: {}\".format(len(benign_flow_df)))\n",
    "\n",
    "    # assign random identifier\n",
    "    benign_identifier = (np.random.rand(len(benign_flow_df))*benign_user_num).astype(int)\n",
    "    benign_flow_df.insert(0, \"id\", benign_identifier)\n",
    "    \n",
    "    benign_flow_np = benign_flow_df.values\n",
    "    X, y = benign_flow_np[:, 1:-1], benign_flow_np[:, 0]\n",
    "    X_train, X_benign_test, y_train, y_benign_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    np.save(\"{}/{}_train.npy\".format(save_dir, basename), np.c_[y_train, X_train])\n",
    "    np.save(\"{}/{}_benign_test.npy\".format(save_dir, basename), np.c_[y_benign_test, X_benign_test])\n",
    "    \n",
    "    # get the malicious flows\n",
    "    malicious_flow_df = clean_df[clean_df['label'] != \"Benign\"]\n",
    "    malicious_flows_list.append(malicious_flow_df)\n",
    "    malicious_flow_nums.append(len(malicious_flow_df))\n",
    "    print(\"Number of malicious data: {}\".format(len(malicious_flow_df)))\n",
    "    \n",
    "print(\"\\nTotal Statistics\\n\\tBenign Flows: {}({:.2f}%)\\n\\tMalicious Flows: {}({:.2f}%)\"\n",
    "      .format(sum(benign_flow_nums), sum(benign_flow_nums)/(sum(benign_flow_nums)+sum(malicious_flow_nums))*100,\n",
    "             sum(malicious_flow_nums), sum(malicious_flow_nums)/(sum(benign_flow_nums)+sum(malicious_flow_nums))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of attack:\n",
      "\n",
      "label\n",
      "Bot                      286191\n",
      "Brute Force -Web            611\n",
      "Brute Force -XSS            230\n",
      "DDOS attack-HOIC         686012\n",
      "DDOS attack-LOIC-UDP       1730\n",
      "DoS attacks-GoldenEye     41508\n",
      "DoS attacks-Slowloris     10990\n",
      "FTP-BruteForce           193354\n",
      "SQL Injection                87\n",
      "SSH-Bruteforce           187589\n",
      "Name: label, dtype: int64\n",
      "--------------------------------------------------\n",
      "Total types of attack: 10\n"
     ]
    }
   ],
   "source": [
    "# merge the malicious flows\n",
    "merged_malicious_df = pd.concat(malicious_flows_list, ignore_index=True)\n",
    "merged_malicious_df.insert(0, \"id\", 0)\n",
    "\n",
    "attack_num = merged_malicious_df.groupby('label')['label'].count()\n",
    "print(\"Statistics of attack:\\n\\n{}\".format(attack_num))\n",
    "print(\"-\"*50+\"\\nTotal types of attack: {}\".format(len(attack_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of attacker:\n",
      "\n",
      "Bot                 \t412\n",
      "Brute Force -Web    \t13\n",
      "Brute Force -XSS    \t8\n",
      "DDOS attack-HOIC    \t666\n",
      "DDOS attack-LOIC-UDP\t24\n",
      "DoS attacks-GoldenEye\t142\n",
      "DoS attacks-Slowloris\t68\n",
      "FTP-BruteForce      \t332\n",
      "SQL Injection       \t4\n",
      "SSH-Bruteforce      \t326\n",
      "--------------------------------------------------\n",
      "Total number of attackers: 1995\n"
     ]
    }
   ],
   "source": [
    "malicious_user_num = 2000 \n",
    "\n",
    "temperature = 0.55\n",
    "adjusted_attack_num = [n**temperature for n in attack_num]\n",
    "weight = [n/sum(adjusted_attack_num) for n in adjusted_attack_num]\n",
    "assigned_malicious_user_num = [int(w*malicious_user_num) for w in weight]\n",
    "\n",
    "print(\"Statistics of attacker:\\n\")\n",
    "for i, k in enumerate(attack_num.keys()):\n",
    "    print(\"{:20s}\\t{}\".format(k, assigned_malicious_user_num[i]))\n",
    "print(\"-\"*50+\"\\nTotal number of attackers: {}\".format(sum(assigned_malicious_user_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot attackers are assigned to id 10000~10411\n",
      "Brute Force -Web attackers are assigned to id 10412~10424\n",
      "Brute Force -XSS attackers are assigned to id 10425~10432\n",
      "DDOS attack-HOIC attackers are assigned to id 10433~11098\n",
      "DDOS attack-LOIC-UDP attackers are assigned to id 11099~11122\n",
      "DoS attacks-GoldenEye attackers are assigned to id 11123~11264\n",
      "DoS attacks-Slowloris attackers are assigned to id 11265~11332\n",
      "FTP-BruteForce attackers are assigned to id 11333~11664\n",
      "SQL Injection attackers are assigned to id 11665~11668\n",
      "SSH-Bruteforce attackers are assigned to id 11669~11994\n"
     ]
    }
   ],
   "source": [
    "user_id_start = benign_user_num\n",
    "for i, (k, v) in enumerate(attack_num.items()):\n",
    "    attack_user_num = assigned_malicious_user_num[i]\n",
    "    attack_identifier = (0.9999*np.random.rand(v)*attack_user_num).astype(int) + user_id_start\n",
    "    merged_malicious_df.loc[merged_malicious_df['label'] == k, \"id\"] = attack_identifier\n",
    "    \n",
    "    print(\"{} attackers are assigned to id {}~{}\".format(k, user_id_start, user_id_start+attack_user_num-1))\n",
    "    user_id_start += attack_user_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "malicious_flow_np = merged_malicious_df.values\n",
    "\n",
    "# randomly shuffle the attacks\n",
    "np.random.shuffle(malicious_flow_np)\n",
    "\n",
    "benign_relative_size = [bfn/sum(benign_flow_nums) for bfn in benign_flow_nums]\n",
    "start_idx = 0\n",
    "for i, brs in enumerate(benign_relative_size):\n",
    "    basename = data_files_list[i].split(\"/\")[-1].replace('.csv', '')\n",
    "    flow_num = int(brs * len(malicious_flow_np))\n",
    "    partition_np = malicious_flow_np[start_idx:start_idx+flow_num, :-1]\n",
    "    \n",
    "    np.save(\"{}/{}_attack_test.npy\".format(save_dir, basename), partition_np)\n",
    "    start_idx += flow_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
